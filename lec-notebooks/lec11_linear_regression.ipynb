{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, I am going to use more interactive plots (they look better) so I am using the plotly.express library.  We won't test you on this but it's good to know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 11\n",
    "\n",
    "In this lecture, we derive the equation for linear regression using the correlation coefficient $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap From Last Lecture\n",
    "\n",
    "In the previous lecture, we introduced the correlation coefficient: \n",
    "\n",
    "\\begin{align}\n",
    "r \n",
    "& = \\text{Mean}\\left(\\text{StandardUnits}(x) *  \\text{StandardUnits}(y)\\right)\\\\\n",
    "& = \\frac{1}{n} \\sum_{i=1}^n \\text{StandardUnits}(x_i) *  \\text{StandardUnits}(y_i)\\\\\n",
    "& = \\frac{1}{n}\\sum_{i=1}^n \\left( \\frac{x_i - \\text{Mean}(x)}{\\text{Stdev}(x)} \\right) * \\left( \\frac{y_i - \\text{Mean}(y)}{\\text{Stdev}(y)} \\right) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented the correlation coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(x):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(t, x, y):\n",
    "    \"\"\"t is a table; x and y are column labels\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built an intuition about the correlation coefficient using the following code which you don't need to understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_correlated_data(r, n=500):\n",
    "    \"Generate a a table with columns x and y with a correlation of approximately r\"\n",
    "    x = np.random.normal(0, 1, n)\n",
    "    z = np.random.normal(0, 1, n)\n",
    "    y = r*x + (np.sqrt(1-r**2))*z\n",
    "    return Table().with_columns(\"x\", x, \"y\", y)\n",
    "\n",
    "def r_scatter(r, n=500, ax=None):\n",
    "    plots.figure(figsize=(5,5))\n",
    "    \"Generate a scatter plot with a correlation approximately r\"\n",
    "    x = np.random.normal(0, 1, n)\n",
    "    z = np.random.normal(0, 1, n)\n",
    "    y = r*x + (np.sqrt(1-r**2))*z\n",
    "    if ax:        \n",
    "        ax.scatter(x, y, color='darkblue', s=20)\n",
    "        ax.set_xlim(-4, 4)\n",
    "        ax.set_ylim(-4, 4) \n",
    "    else:\n",
    "        plots.scatter(x, y, color='darkblue', s=20)\n",
    "        plots.xlim(-4, 4)\n",
    "        plots.ylim(-4, 4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plots.subplots(2, 3, dpi=80, figsize=(16,9))\n",
    "n = 500\n",
    "r_scatter(0.2, n, ax[0,0])\n",
    "r_scatter(0.5, n, ax[0,1])\n",
    "r_scatter(0.8, n, ax[0,2])\n",
    "r_scatter(-0.2, n, ax[1,0])\n",
    "r_scatter(-0.5, n, ax[1,1])\n",
    "r_scatter(-0.8, n, ax[1,2])\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<center>Return to Slides</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Care when Interpreting the Correlation\n",
    "\n",
    "When computing correlation it is important to always visualize your data first and then consider each of the following issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation does Not Imply Causation\n",
    "\n",
    "We have covered this one extensively at this point.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinearity\n",
    "\n",
    "Low correlation does not imply absence of a relationship. Correlation measures linear relationships.  Data with strong non-linear relationship may have very low correlation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.arange(-4, 4.1, 0.5)\n",
    "nonlinear = Table().with_columns(\n",
    "        'x', new_x,\n",
    "        'y', new_x**2\n",
    "    )\n",
    "nonlinear.scatter('x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly a relationship to this data.  Given the value of $x$ you can easily predict the value of $y$.  What is the correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(nonlinear, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "Outliers can have a significant effect on correlation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = Table().with_columns(\n",
    "        'x', make_array(1, 2, 3, 4),\n",
    "        'y', make_array(1, 2, 3, 4)\n",
    "    )\n",
    "line.scatter('x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(line, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = Table().with_columns(\n",
    "        'x', make_array(1, 2, 3, 4, 5),\n",
    "        'y', make_array(1, 2, 3, 4, 0)\n",
    "    )\n",
    "outlier.scatter('x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ecological Correlations\n",
    "\n",
    "The correlation between aggregated variables (e.g., after grouping) may be much higher than the correlation between the underlying variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2014 = Table.read_table('data/sat2014.csv').sort('State')\n",
    "sat2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2014.scatter('Critical Reading', 'Math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(sat2014, 'Critical Reading', 'Math')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a very strong correlation.  However, each data point corresponds to a large cloud of data points where each person might have had greater variability in their scores.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Understanding the SAT data\n",
    "While we have the data loaded.  Does anyone have a guess which dots correspond to which state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.scatter(sat2014.to_df(), \n",
    "           x = \"Critical Reading\",\n",
    "           y = \"Math\",\n",
    "           hover_name = \"State\",\n",
    "           size = \"Participation Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<center>Return to Slides</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Lines\n",
    "\n",
    "Here we build an intuition about the relationship between the slope of the nearest neighbor line and the correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using the Heights Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Load the family height data\n",
    "families = Table.read_table('data/family_heights.csv')\n",
    "parent_avgs = (families.column('father') + families.column('mother'))/2\n",
    "heights = Table().with_columns(\n",
    "    'Parent Average', parent_avgs,\n",
    "    'Child', families.column('child'),\n",
    ").sort(\"Parent Average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a slightly more robust Nearest Neighbor predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nn_heights(parent_average, window=0.5):\n",
    "    lower_bound = parent_average - window\n",
    "    upper_bound = parent_average + window\n",
    "    similar_child_heights = (\n",
    "        heights\n",
    "            .where(\"Parent Average\", are.between(lower_bound, upper_bound))\n",
    "            .column(\"Child\")\n",
    "    )\n",
    "    if len(similar_child_heights) == 0: #handle the case when there is no data\n",
    "        return np.nan # nan = not a number , a special floating point \"number\"\n",
    "    else:\n",
    "        return np.mean(similar_child_heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions at many different parent heights not just the heights in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_heights = Table().with_column(\"Parent Average\", np.arange(61,74,0.2))\n",
    "test_heights = test_heights.with_column(\n",
    "    \"NN Prediction\", test_heights.apply(nn_heights, \"Parent Average\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot it all\n",
    "fig = px.scatter(heights.to_df(), x=\"Parent Average\", y=\"Child\", height=600)\n",
    "fig.add_scatter(x=test_heights.column(\"Parent Average\"), \n",
    "                y=test_heights.column(\"NN Prediction\"), name=\"NN Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it will be easier to start in standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Transform the heights data into standard units\n",
    "su_heights = Table().with_columns(\n",
    "    \"Parent Average\", standard_units(heights.column(\"Parent Average\")),\n",
    "    \"Child\", standard_units(heights.column(\"Child\")))\n",
    "\n",
    "## Transform the nearest neighbor predictions to standard units\n",
    "su_test_heights = Table().with_columns(\n",
    "    \"Parent Average\", \n",
    "    (test_heights.column(\"Parent Average\") - heights.column(\"Parent Average\").mean()) \n",
    "                        / heights.column(\"Parent Average\").std(),\n",
    "    \"NN Prediction\", \n",
    "    (test_heights.column(\"NN Prediction\") - heights.column(\"Child\").mean()) \n",
    "                        / heights.column(\"Child\").std()) \n",
    "\n",
    "## Plot it all\n",
    "fig = px.scatter(su_heights.to_df(), x=\"Parent Average\", y=\"Child\", height=600)\n",
    "fig.add_scatter(x=su_test_heights.column(\"Parent Average\"), \n",
    "                y=su_test_heights.column(\"NN Prediction\"), name=\"NN Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the correlation we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correlation(heights, \"Parent Average\", \"Child\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we draw a line with that slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = correlation(su_heights, \"Parent Average\", \"Child\")\n",
    "fig = px.scatter(su_heights.to_df(), x=\"Parent Average\", y=\"Child\", height=600)\n",
    "fig.add_scatter(x=su_test_heights.column(\"Parent Average\"), \n",
    "                y=su_test_heights.column(\"NN Prediction\"), \n",
    "                name=\"NN Prediction\")\n",
    "fig.add_scatter(x=np.arange(-3,4,0.1), y= r * np.arange(-3,4,0.1), \n",
    "                name=f\"Line(y={np.round(r,4)} x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Relationship Between Correlation and NN Predictions\n",
    "\n",
    "Here we examine the relationship between the nearest neighbor prediction \"line\" and the correlation for several synthetic datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_nn_predictions(table, x, y, window):\n",
    "    \n",
    "    def nn_prediction(x_val):        \n",
    "        neighbors = table.where(x, are.between(x_val - window, x_val + window)).column(y)\n",
    "        if len(neighbors) == 0:\n",
    "            return np.nan\n",
    "        else: \n",
    "            return np.mean(neighbors)   \n",
    "        \n",
    "    return table.apply(nn_prediction, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_line(slope):\n",
    "    plots.axline(xy1=(0,0), slope=slope)    \n",
    "\n",
    "def draw_vline(x_pos):\n",
    "    plots.axvline(x_pos, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Todo**\n",
    "- use `make_correlated_data` to create a table with data with r=0.99\n",
    "- plot the data\n",
    "- compute the nn_predictions and add the nn predictions as a column\n",
    "- plot the nn predictions\n",
    "- add a line with a slope of 1 \n",
    "\n",
    "Now change r to lower values (e.g. 0.5). What is happening?\n",
    "- draw a vertical line at x=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's do this with the family data\n",
    "- load the data\n",
    "- compute the parent average\n",
    "- convert to SU\n",
    "- compute the nn predictions\n",
    "- plot them\n",
    "- compute the correlation\n",
    "- add a line with slope=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "families = Table.read_table('data/family_heights.csv')\n",
    "parent_avgs = (families.column('father') + families.column('mother'))/2\n",
    "heights = Table().with_columns('Parent Average', parent_avgs, 'Child', families.column('child'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<center>Return to Slides</center>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the linear regression line\n",
    "\n",
    "In standard units we developed a simple equation for the regression line:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{SU}(y_\\text{predicted}) = r * \\text{SU}(x_\\text{new})\n",
    "\\end{align}\n",
    "\n",
    "where $r$ is the correlation coefficient and $\\text{SU}$ is the standard units:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{SU}(y_\\text{predicted}) & = \\frac{y_\\text{predicted} - \\text{Mean}(y)}{\\text{Stdev}(y)} \\\\\n",
    "\\text{SU}(x_\\text{new}) &= \\frac{x_\\text{new} - \\text{Mean}(x)}{\\text{Stdev}(x)}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "Here we use $x_\\text{new}$ to indicate a new $x$ value for which we want to make a prediction  $y_\\text{predicted}$.\n",
    "\n",
    "We would like to express this line in the original units of the data.  We can do that by substituting the definition of standard units:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{y_\\text{predicted} - \\text{Mean}(y)}{\\text{Stdev}(y)} = r *  \\frac{x_\\text{new} - \\text{Mean}(x)}{\\text{Stdev}(x)}\n",
    "\\end{align}\n",
    "\n",
    "While this equation does desribe a line it would look a little nicer in the form:\n",
    "\n",
    "\\begin{align}\n",
    "y_\\text{predicted} = \\text{slope} * x_\\text{new}  + \\text{intercept}\n",
    "\\end{align}\n",
    "\n",
    "Let's do some algebra to get that equation:\n",
    "$$\n",
    "\\require{color}\n",
    "\\definecolor{comment}{RGB}{200,100,50}\n",
    "\\begin{align}\n",
    "\\frac{y_\\text{predicted} - \\text{Mean}(y)}{\\text{Stdev}(y)} &= r *  \\frac{x_\\text{new} - \\text{Mean}(x)}{\\text{Stdev}(x)}\\\\\n",
    "\\frac{y_\\text{predicted} - \\text{Mean}(y)}{\\text{Stdev}(y)} &= r * \\frac{1}{\\text{Stdev}(x)} x_\\text{new} - r * \\frac{1}{\\text{Stdev}(x)}\\text{Mean}(x)  & \\color{comment} \\text{Expanding the right side}\\\\\n",
    "y_\\text{predicted} - \\text{Mean}(y) &= r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)} x_\\text{new} - r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\text{Mean}(x) &  \\color{comment} \\text{Multiplying by $\\text{Stdev}(y)$}\\\\\n",
    "y_\\text{predicted} &= r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)} x_\\text{new} + \\text{Mean}(y) - r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\text{Mean}(x) &  \\color{comment} \\text{Adding $\\text{Mean}(y)$}\\\\\n",
    "y_\\text{predicted} &= \\left(r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\right) x_\\text{new} + \\left(\\text{Mean}(y) - r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\text{Mean}(x)\\right) &  \\color{comment} \\text{Rearranging Terms}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This means we can define the slope and intercept as:\n",
    "\\begin{align}\n",
    "\\text{slope} &= r * \\frac{\\text{Stdev}(y)}{\\text{Stdev}(x)}\\\\\n",
    "\\text{intercept} & = \\text{Mean}(y) - \\text{slope} * \\text{Mean}(x)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Linear Regression\n",
    "\n",
    "Using the above equations implement the slope and intercept functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(t, x, y):\n",
    "    \"\"\"Computes the slope of the regression line\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercept(t, x, y):\n",
    "    \"\"\"Computes the intercept of the regression line\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = make_correlated_data(0.5)\n",
    "slope(example, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the slope and intercept for the heights dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_slope = ...\n",
    "heights_intercept = ...\n",
    "[heights_slope, heights_intercept]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    \n",
    "```python\n",
    "heights_slope = slope(heights, 'Parent Average', 'Child')\n",
    "heights_intercept = intercept(heights, 'Parent Average', 'Child')\n",
    "[heights_slope, heights_intercept]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the regression predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = heights.with_column(\n",
    "    'Regression Prediction', \n",
    "    ...\n",
    ")\n",
    "heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    \n",
    "```python\n",
    "heights = heights.with_column(\n",
    "    'Regression Prediction', \n",
    "    predicted_heights_slope*heights.column('Parent Average') + predicted_heights_intercept\n",
    ")\n",
    "heights\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights.scatter('Parent Average')\n",
    "#draw_line(heights_intercept, heights_slope)\n",
    "plots.xlim(60,75)\n",
    "plots.ylim(55,80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<center>Return to Slides</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Question: Exam Score Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-axis: midterm scores\n",
    "midterm_mean = 70\n",
    "midterm_sd = 10\n",
    "\n",
    "# Y-axis: final scores\n",
    "final_mean = 50\n",
    "final_sd = 12\n",
    "\n",
    "# Correlation (relates X to Y values)\n",
    "corr = 0.75\n",
    "\n",
    "# X value\n",
    "midterm_student = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midterm_student_su = (midterm_student - midterm_mean) / midterm_sd\n",
    "midterm_student_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_student_su = midterm_student_su * corr\n",
    "final_student_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_student = final_student_su * final_sd + final_mean\n",
    "final_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
